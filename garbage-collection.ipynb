{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "garbage-collection.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "LQd9qAxJc0CP"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob, os, random\n",
        "import torch\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DgIrIORevUz",
        "outputId": "6c4bc23d-15ef-4045-bc1f-f6f329b23289"
      },
      "source": [
        "!git clone https://github.com/swatidamele/FinalProject.git"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'FinalProject' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "Y_jkG-V-c0CS",
        "outputId": "2ee2e4bb-1bf9-4b8c-c3fe-48447b5654be"
      },
      "source": [
        "data_dir  = 'https://github.com/swatidamele/FinalProject/tree/main/GarbageClassification'\n",
        "\n",
        "classes = os.listdir(data_dir)\n",
        "print(classes)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-b46f39b967ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_dir\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m'https://github.com/swatidamele/FinalProject/tree/main/GarbageClassification'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://github.com/swatidamele/FinalProject/tree/main/GarbageClassification'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hmJzcg3Jc0CU"
      },
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transformations = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
        "\n",
        "dataset = ImageFolder(data_dir, transform = transformations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "V8iciYlrc0CU"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_sample(img, label):\n",
        "    print(\"Label:\", dataset.classes[label], \"(Class No: \"+ str(label) + \")\")\n",
        "    plt.imshow(img.permute(1, 2, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YXU4aGCUc0CV"
      },
      "source": [
        "img, label = dataset[12]\n",
        "show_sample(img, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "21ERPyWwc0CW"
      },
      "source": [
        "base_path = '/kaggle/input/garbage-classification/Garbage classification/Garbage classification'\n",
        "\n",
        "img_list = glob.glob(os.path.join(base_path, '*/*.jpg'))\n",
        "\n",
        "print(len(img_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9zIqdxvsc0CW"
      },
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QOKcs4f9c0CX"
      },
      "source": [
        "split_1 = int(0.8 * len(img_list))\n",
        "split_2 = int(0.9 * len(img_list))\n",
        "train_data = img_list[:split_1]\n",
        "dev_data = img_list[split_1:split_2]\n",
        "test_data = img_list[split_2:]\n",
        "print(\"Train Data\")\n",
        "print(len(train_data))\n",
        "print(\"Dev Data\")\n",
        "print(len(dev_data))\n",
        "print(\"Test Data\")\n",
        "print(len(test_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8gQEjoWDc0CY"
      },
      "source": [
        "for i, img_path in enumerate(random.sample(img_list, 6)):\n",
        "    img = load_img(img_path)\n",
        "    img = img_to_array(img, dtype=np.uint8)\n",
        "\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(img.squeeze())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JhgYBo0Oc0CY"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_path,\n",
        "    target_size=(300, 300),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    seed=0\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    base_path,\n",
        "    target_size=(300, 300),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    seed=0\n",
        ")\n",
        "\n",
        "\n",
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gb1Az8a_c0CZ"
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(300, 300, 3)),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "\n",
        "    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    \n",
        "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    \n",
        "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(64, activation='relu'),\n",
        "\n",
        "    Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "A_Oq1gLfc0Ca"
      },
      "source": [
        "model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}